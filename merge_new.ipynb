{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_df = pd.read_csv('ford_recalls_last.csv')\n",
    "investigation_df = pd.read_csv('merged_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Manufacturer', 'NHTSACampaignNumber', 'ReportReceivedDate',\n",
       "       'Component', 'Summary', 'Consequence', 'Remedy', 'Notes', 'ModelYear',\n",
       "       'Make', 'Model', 'parkIt', 'parkOutSide', 'overTheAirUpdate',\n",
       "       'NHTSAActionNumber'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['odiNumber', 'crash', 'fire', 'numberOfInjuries', 'numberOfDeaths',\n",
       "       'dateOfIncident', 'dateComplaintFiled', 'vin', 'components',\n",
       "       'summary_complaint', 'products', 'Model', 'ModelYear',\n",
       "       'NHTSA_ACTION_NUMBER', 'MODEL', 'YEAR', 'component_name', 'open_date',\n",
       "       'close_date', 'campaign_number', 'subject', 'summary_investigation',\n",
       "       'similarity_score', 'recall_status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "investigation_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "complaints_df = pd.read_csv(\"ford_complaints.csv\")\n",
    "investigations_df = pd.read_csv(\"investigation_with_recall_status.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    if pd.isnull(text):\n",
    "        return \"\"\n",
    "    return text.lower().strip()\n",
    "\n",
    "complaints_df['Model'] = complaints_df['Model'].apply(preprocess_text)\n",
    "complaints_df['ModelYear'] = complaints_df['ModelYear'].astype(str)\n",
    "\n",
    "investigations_df['MODEL'] = investigations_df['MODEL'].apply(preprocess_text)\n",
    "investigations_df['YEAR'] = investigations_df['YEAR'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "complaint_embeddings = model.encode(complaints_df['summary'].fillna(\"\").tolist(), convert_to_tensor=False)\n",
    "investigation_embeddings = model.encode(investigations_df['SUMMARY'].fillna(\"\").tolist(), convert_to_tensor=False)\n",
    "\n",
    "complaints_df['summary_embedding'] = list(complaint_embeddings)\n",
    "investigations_df['summary_embedding'] = list(investigation_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, complaint in complaints_df.iterrows():\n",
    "    filtered_investigations = investigations_df[\n",
    "        (investigations_df['MODEL'] == complaint['Model']) &\n",
    "        (investigations_df['YEAR'] == complaint['ModelYear'])\n",
    "    ]\n",
    "\n",
    "    if filtered_investigations.empty:\n",
    "        continue \n",
    "\n",
    "    similarities = cosine_similarity(\n",
    "        [complaint['summary_embedding']],\n",
    "        list(filtered_investigations['summary_embedding'])\n",
    "    )[0]\n",
    "\n",
    "    threshold = 0.7\n",
    "    for idx, similarity in enumerate(similarities):\n",
    "        if similarity >= threshold:\n",
    "            investigation = filtered_investigations.iloc[idx]\n",
    "            merged_results.append({\n",
    "                'odiNumber': complaint['odiNumber'],\n",
    "                'crash': complaint['crash'],\n",
    "                'fire': complaint['fire'],\n",
    "                'numberOfInjuries': complaint['numberOfInjuries'],\n",
    "                'numberOfDeaths': complaint['numberOfDeaths'],\n",
    "                'dateOfIncident': complaint['dateOfIncident'],\n",
    "                'dateComplaintFiled': complaint['dateComplaintFiled'],\n",
    "                'vin': complaint['vin'],\n",
    "                'components': complaint['components'],\n",
    "                'summary_complaint': complaint['summary'],\n",
    "                'products': complaint['products'],\n",
    "                'Model': complaint['Model'],\n",
    "                'ModelYear': complaint['ModelYear'],\n",
    "                'NHTSA_ACTION_NUMBER': investigation['NHTSA ACTION NUMBER'],\n",
    "                'MODEL': investigation['MODEL'],\n",
    "                'YEAR': investigation['YEAR'],\n",
    "                'component_name': investigation['COMPNAME'],\n",
    "                'open_date': investigation['ODATE'],\n",
    "                'close_date': investigation['CDATE'],\n",
    "                'campaign_number': investigation['CAMPNO'],\n",
    "                'subject': investigation['SUBJECT'],\n",
    "                'summary_investigation': investigation['SUMMARY'],\n",
    "                'similarity_score': similarity,\n",
    "                'recall_status': investigation['recall_status']\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.DataFrame(merged_results)\n",
    "\n",
    "merged_df.drop_duplicates(inplace=True)\n",
    "\n",
    "merged_df.to_csv(\"merged_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning recall status and adding recall date to the merged data\n",
    "import numpy as np\n",
    "investigation_df = pd.read_csv('merged_2.csv')\n",
    "recall_df = pd.read_csv('ford_recalls_last.csv')\n",
    "\n",
    "def get_recall_info(row):\n",
    "    match = recall_df[\n",
    "        (recall_df['NHTSA_Campaign_Number'] == row['NHTSA_Campaign_Number']) | \n",
    "        (recall_df['NHTSA_ACTION_NUMBER'] == row['NHTSA_ACTION_NUMBER'])\n",
    "    ]\n",
    "    \n",
    "    if not match.empty:\n",
    "        return pd.Series([1, match['ReportReceivedDate'].values[0]])\n",
    "    else:\n",
    "        return pd.Series([0, -1])\n",
    "\n",
    "investigation_df[['recall_status', 'ReportReceivedDate']] = investigation_df.apply(get_recall_info, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "investigation_df['dateOfIncident'] = pd.to_datetime(investigation_df['dateOfIncident'], format='%m/%d/%Y')\n",
    "investigation_df['dateComplaintFiled'] = pd.to_datetime(investigation_df['dateComplaintFiled'], format='%m/%d/%Y')\n",
    "investigation_df['open_date'] = pd.to_datetime(investigation_df['open_date'], format='%Y%m%d')\n",
    "investigation_df['close_date'] = pd.to_datetime(investigation_df['close_date'], format='%Y%m%d')\n",
    "investigation_df['ReportReceivedDate'] = pd.to_datetime(investigation_df['ReportReceivedDate'], format='%d/%m/%Y', errors='coerce')\n",
    "\n",
    "#Calculate \"incident_filing_lag\" as the difference between \"dateOfIncident\" and \"dateComplaintFiled\"\n",
    "investigation_df['incident_filing_lag'] = (investigation_df['dateComplaintFiled'] - investigation_df['dateOfIncident']).dt.days\n",
    "\n",
    "# Calculate \"days_taken_in_investigation\" as the difference between \"open_date\" and \"close_date\"\n",
    "investigation_df['days_taken_in_investigation'] = (investigation_df['close_date'] - investigation_df['open_date']).dt.days\n",
    "\n",
    "#Calculate \"days_taken_in_recall\" as the difference between \"dateComplaintFiled\" and \"ReportReceivedDate\"\n",
    "investigation_df['days_taken_in_recall'] = (investigation_df['ReportReceivedDate'] - investigation_df['dateComplaintFiled']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "investigation_df.to_csv('merged_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
